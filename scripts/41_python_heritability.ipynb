{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ae475a-ef49-491a-a7dd-a19b1d65783a",
   "metadata": {},
   "source": [
    "# 41. Python version of heritability analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b4e831-03e5-4fd2-b64c-470f363f7df8",
   "metadata": {},
   "source": [
    "Note here we set `df_row` to 0 because we're just testing code on first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfe5b8db-12a1-4b8e-b893-0d3b83850641",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ab3e2-524f-47a9-aff5-01bc1bcda914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from pgenlib import PgenReader\n",
    "import limix.her\n",
    "\n",
    "# -----------------------------\n",
    "# Parameters (Adjust as needed)\n",
    "# -----------------------------\n",
    "#window_sizes = [10000, 100000, 1000000]  # Window sizes in base pairs\n",
    "window_sizes = [10000]\n",
    "chunk_start = 1                           # Start index for CpG sites (1-based)\n",
    "chunk_end = 50                            # End index for CpG sites (1-based)\n",
    "benchmark = True                         # Whether to measure timing\n",
    "\n",
    "# -----------------------------\n",
    "# Paths (Adjust these paths according to your data)\n",
    "# -----------------------------\n",
    "\n",
    "df_csv_path = \"/dcs04/lieber/statsgen/mnagle/mwas/CpGWAS/scripts/09.5-OUT_matched_SNP_meth_cov_chunked_JHPCE.csv\"\n",
    "output_dir = \"./41-OUT_heritability_a1\"\n",
    "\n",
    "if benchmark:\n",
    "    start_time_total = time.time()\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "os.chdir(output_dir)\n",
    "\n",
    "# Read the data frame containing paths to SNP and methylation data\n",
    "df = pd.read_csv(df_csv_path)\n",
    "\n",
    "# Processing the first row as per df_row in R script\n",
    "df_row = 0  # Adjust as needed\n",
    "\n",
    "# Extract paths from the data frame\n",
    "gwas_dir = os.path.dirname(df.loc[df_row, 'SNP_data'])\n",
    "methylation_file = df.loc[df_row, 'modified_methylation_data']\n",
    "\n",
    "methylation_file = methylation_file.replace(\"/dcs04/lieber/statsgen/shizhong/michael/mwas/pheno/\", \"/dcs04/lieber/statsgen/mnagle/mwas/pheno/\")\n",
    "\n",
    "methylation_file = methylation_file.replace(\"rda\", \"csv\")\n",
    "methylation_file = methylation_file.replace(\"rds\", \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f680da3-ebce-4b3c-a334-5a88d32c2e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromosome = df.loc[df_row, 'Chr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bba8597-834d-4aa6-8e3b-cd40740293d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chromosome: 1\n",
      "Genotype Directory: /dcs04/lieber/statsgen/shizhong/michael/mwas/gwas\n",
      "Methylation File: /dcs04/lieber/statsgen/mnagle/mwas/pheno/caud/out/chr1_AA_8982-28981.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"Processing Chromosome: {chromosome}\")\n",
    "print(f\"Genotype Directory: {gwas_dir}\")\n",
    "print(f\"Methylation File: {methylation_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d0203e-75bc-4fbd-9ebc-3507c2125eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methylation data loaded from '/dcs04/lieber/statsgen/mnagle/mwas/pheno/caud/out/chr1_AA_8982-28981.csv'.\n",
      "'sample_id' column confirmed and converted to string.\n",
      "CpG positions extracted from column names.\n",
      "Selected CpG Columns: ['pos_1069461', 'pos_1069467', 'pos_1069470', 'pos_1069477', 'pos_1069484', 'pos_1069498', 'pos_1069506', 'pos_1069516', 'pos_1069530', 'pos_1069533', 'pos_1069539', 'pos_1069544', 'pos_1069569', 'pos_1069573', 'pos_1069591', 'pos_1069599', 'pos_1069601', 'pos_1069603', 'pos_1069613', 'pos_1069626', 'pos_1069629', 'pos_1069635', 'pos_1069637', 'pos_1069645', 'pos_1069651', 'pos_1069653', 'pos_1069669', 'pos_1069682', 'pos_1069691', 'pos_1069693', 'pos_1069697', 'pos_1069699', 'pos_1069707', 'pos_1069715', 'pos_1069720', 'pos_1069778', 'pos_1069790', 'pos_1069800', 'pos_1069810', 'pos_1069819', 'pos_1069829', 'pos_1069831', 'pos_1069835', 'pos_1069846', 'pos_1069855', 'pos_1069859', 'pos_1069874', 'pos_1069882', 'pos_1069890', 'pos_1069906']\n",
      "Selected CpG Positions: [1069461, 1069467, 1069470, 1069477, 1069484, 1069498, 1069506, 1069516, 1069530, 1069533, 1069539, 1069544, 1069569, 1069573, 1069591, 1069599, 1069601, 1069603, 1069613, 1069626, 1069629, 1069635, 1069637, 1069645, 1069651, 1069653, 1069669, 1069682, 1069691, 1069693, 1069697, 1069699, 1069707, 1069715, 1069720, 1069778, 1069790, 1069800, 1069810, 1069819, 1069829, 1069831, 1069835, 1069846, 1069855, 1069859, 1069874, 1069882, 1069890, 1069906]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Load Methylation Data\n",
    "# -----------------------------\n",
    "try:\n",
    "    # Methylation data has 'sample_id' as the first column and CpG positions as other columns\n",
    "    methylation_df = pd.read_csv(methylation_file)\n",
    "    print(f\"Methylation data loaded from '{methylation_file}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading methylation file '{methylation_file}': {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Ensure 'sample_id' is treated as a string\n",
    "if 'sample_id' not in methylation_df.columns:\n",
    "    print(f\"'sample_id' column not found in methylation data. Exiting.\")\n",
    "    exit(1)\n",
    "\n",
    "methylation_df['sample_id'] = methylation_df['sample_id'].astype(str)\n",
    "print(\"'sample_id' column confirmed and converted to string.\")\n",
    "\n",
    "# Extract CpG columns (all columns except 'sample_id')\n",
    "cpg_columns = methylation_df.columns.drop('sample_id')\n",
    "\n",
    "# Extract numeric CpG positions from column names (e.g., 'pos_1069461' -> 1069461)\n",
    "try:\n",
    "    cpg_positions = [int(col.split('_')[1]) for col in cpg_columns]\n",
    "    print(\"CpG positions extracted from column names.\")\n",
    "except IndexError as e:\n",
    "    print(f\"Error parsing CpG positions in column names: {e}\")\n",
    "    exit(1)\n",
    "except ValueError as e:\n",
    "    print(f\"Non-integer CpG position found in column names: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Create a mapping from column names to positions\n",
    "cpg_col_to_pos = dict(zip(cpg_columns, cpg_positions))\n",
    "\n",
    "# Select the CpG positions for the specified chunk\n",
    "# Note: Python uses 0-based indexing\n",
    "selected_cpg_cols = cpg_columns[chunk_start - 1:chunk_end]\n",
    "selected_cpg_positions = [cpg_col_to_pos[col] for col in selected_cpg_cols]\n",
    "\n",
    "print(f\"Selected CpG Columns: {selected_cpg_cols.tolist()}\")\n",
    "print(f\"Selected CpG Positions: {selected_cpg_positions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccc085ff-e136-4a0d-80ff-84ba2e83521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a17d15b1-e659-4654-b661-bdedf8da603e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected CpG Site: pos_1069906 at position 1069906\n",
      "Selected Window Size: 10000 bp\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Select a Single CpG Site and Window Size for Testing\n",
    "# -----------------------------\n",
    "# For initial testing, we'll process the first CpG site and the first window size\n",
    "cpg_col = selected_cpg_cols[i]\n",
    "cpg_pos = selected_cpg_positions[i]\n",
    "w = window_sizes[0]\n",
    "\n",
    "print(f\"\\nSelected CpG Site: {cpg_col} at position {cpg_pos}\")\n",
    "print(f\"Selected Window Size: {w} bp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4b82d37-f9a0-4a42-a65d-656147dffecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with non-missing methylation data: 164\n",
      "Genomic window: 1059906 - 1079906 bp\n",
      "All necessary PLINK 2 files found.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Extract Methylation Data for the Selected CpG Site\n",
    "# -----------------------------\n",
    "pheno_df = methylation_df[['sample_id', cpg_col]].dropna()\n",
    "y = pheno_df[cpg_col].values\n",
    "sample_ids = pheno_df['sample_id'].values\n",
    "n_samples = len(sample_ids)\n",
    "\n",
    "print(f\"Number of samples with non-missing methylation data: {n_samples}\")\n",
    "\n",
    "if n_samples == 0:\n",
    "    print(\"No samples with non-missing methylation data. Exiting.\")\n",
    "    exit(1)\n",
    "\n",
    "# -----------------------------\n",
    "# Define Genomic Window\n",
    "# -----------------------------\n",
    "p1 = max(cpg_pos - w, 0)\n",
    "p2 = cpg_pos + w\n",
    "\n",
    "print(f\"Genomic window: {p1} - {p2} bp\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load Genotype Data for the Specified Chromosome\n",
    "# -----------------------------\n",
    "pgen_prefix = os.path.join(gwas_dir, f\"libd_chr{chromosome}\")\n",
    "pgen_file = f\"{pgen_prefix}.pgen\"\n",
    "pvar_file = f\"{pgen_prefix}.pvar\"\n",
    "psam_file = f\"{pgen_prefix}.psam\"\n",
    "\n",
    "# Check if all necessary PLINK 2 files exist\n",
    "if not all(os.path.exists(f) for f in [pgen_file, pvar_file, psam_file]):\n",
    "    print(\"One or more PLINK 2 files are missing. Exiting.\")\n",
    "    exit(1)\n",
    "\n",
    "print(\"All necessary PLINK 2 files found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78f1c49e-a3b8-40b6-896f-809cd5e2e4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genotype sample IDs loaded from .psam file.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Read Sample IDs from .psam File\n",
    "# -----------------------------\n",
    "try:\n",
    "    psam_df = pd.read_csv(psam_file, sep='\\t')\n",
    "    if '#IID' not in psam_df.columns:\n",
    "        print(f\"'#IID' column not found in .psam file '{psam_file}'. Exiting.\")\n",
    "        exit(1)\n",
    "    geno_sample_ids = psam_df['#IID'].astype(str).values\n",
    "    print(\"Genotype sample IDs loaded from .psam file.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading .psam file '{psam_file}': {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Create a mapping from sample ID to index in genotype data\n",
    "sample_id_to_index = {sid: idx for idx, sid in enumerate(geno_sample_ids)}\n",
    "\n",
    "# Get genotype indices for samples present in methylation data\n",
    "geno_indices = [sample_id_to_index[sid] for sid in sample_ids if sid in sample_id_to_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b695a15-5a0c-4fa9-886a-d856bef81251",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not geno_indices:\n",
    "    print(\"No matching samples between genotype and methylation data. Exiting.\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"Number of matching samples: {len(geno_indices)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Read SNP Positions from .pvar File\n",
    "# -----------------------------\n",
    "try:\n",
    "    pvar_df = pd.read_csv(pvar_file, sep='\\t', comment='#',\n",
    "                          names=['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT'])\n",
    "    print(\"SNP positions loaded from .pvar file.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading .pvar file '{pvar_file}': {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Subset SNPs within the genomic window\n",
    "snps_in_window = pvar_df[(pvar_df['POS'] >= p1) & (pvar_df['POS'] <= p2)]\n",
    "\n",
    "if snps_in_window.empty:\n",
    "    print(\"No SNPs found within the genomic window. Exiting.\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"Number of SNPs within the window: {len(snps_in_window)}\")\n",
    "\n",
    "# Get variant indices (0-based)\n",
    "variant_indices = snps_in_window.index.values\n",
    "\n",
    "if benchmark:\n",
    "    start_time_total = time.time()\n",
    "# Initialize PgenReader with sample_subset\n",
    "# PgenReader expects the filename as bytes\n",
    "geno_indices = sorted(geno_indices)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize PgenReader with sample_subset\n",
    "pgr = PgenReader(pgen_file.encode('utf-8'), sample_subset=np.array(geno_indices, dtype=np.uint32))\n",
    "\n",
    "# Allocate buffer: rows=variants, cols=samples\n",
    "geno_buffer = np.empty((len(variant_indices), n_samples), dtype=np.int32)\n",
    "\n",
    "# Read each variant and populate the buffer\n",
    "for var_idx, variant_idx in enumerate(variant_indices):\n",
    "    # Read genotype for the current variant\n",
    "    # allele_idx=1 corresponds to the alternate allele count\n",
    "    pgr.read(variant_idx, geno_buffer[var_idx, :], allele_idx=1)\n",
    "\n",
    "print(\"Genotype data successfully read and stored in buffer.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Benchmarking: Genotype Reading Time\n",
    "# -----------------------------\n",
    "if benchmark:\n",
    "    geno_time = time.time() - start_time_total\n",
    "    print(f\"Genotype reading time: {geno_time:.2f} seconds\")\n",
    "\n",
    "# -----------------------------\n",
    "# Check number of SNPs\n",
    "# -----------------------------\n",
    "if len(snps_in_window) < 2:\n",
    "    print(\"Only one SNP in window; skipping heritability estimation.\")\n",
    "    exit(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15718ff7-738a-42dd-b81b-58d59fd92b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_buffer_backup = geno_buffer # we need to debug and figure out why geno_buffer is still all integer values even after imputing NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4c3edf6-fad8-4685-bfd4-eaae77a8bc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing genotype data.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Standardize Genotypes\n",
    "# -----------------------------\n",
    "print(\"Standardizing genotype data.\")\n",
    "M = geno_buffer.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36e8a69a-fa9e-4fef-81a8-82081dac3225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing genotype data detected. Imputing missing values with mean genotype.\n",
      "  Imputed missing values for SNP 1 with mean genotype 0.69.\n",
      "  Imputed missing values for SNP 2 with mean genotype 0.96.\n",
      "  Imputed missing values for SNP 3 with mean genotype 0.99.\n",
      "  Imputed missing values for SNP 4 with mean genotype 1.07.\n",
      "Standardizing genotype data.\n",
      "Genotype data standardized.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Check for Missing Data and Impute\n",
    "# -----------------------------\n",
    "if np.any(geno_buffer == -9):\n",
    "    print(\"Missing genotype data detected. Imputing missing values with mean genotype.\")\n",
    "    # Replace missing genotypes (-9) with the mean genotype for each SNP in M\n",
    "    for var in range(M.shape[0]):\n",
    "        missing = M[var, :] == -9\n",
    "        if np.any(missing):\n",
    "            non_missing = M[var, :] != -9\n",
    "            if np.any(non_missing):\n",
    "                mean_geno = np.mean(M[var, non_missing])\n",
    "                M[var, missing] = mean_geno\n",
    "                print(f\"  Imputed missing values for SNP {var + 1} with mean genotype {mean_geno:.2f}.\")\n",
    "            else:\n",
    "                # If all genotypes are missing, impute with 0\n",
    "                M[var, missing] = 0\n",
    "                print(f\"  All genotypes missing for SNP {var + 1}. Imputed with 0.\")\n",
    "    \n",
    "    # Check for NaNs after imputation\n",
    "    if np.isnan(M).any():\n",
    "        nan_indices = np.argwhere(np.isnan(M))\n",
    "        print(f\"NaNs found at positions: {nan_indices}\")\n",
    "        exit(1)  # Stop execution to address the issue\n",
    "\n",
    "# -----------------------------\n",
    "# Standardize Genotypes\n",
    "# -----------------------------\n",
    "print(\"Standardizing genotype data.\")\n",
    "mu = np.mean(M, axis=0)\n",
    "sigma = np.std(M, axis=0, ddof=1)\n",
    "sigma[sigma == 0] = 1  # Avoid division by zero\n",
    "S = (M - mu) / sigma\n",
    "S = np.nan_to_num(S)\n",
    "print(\"Genotype data standardized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a4c36ff-edca-4864-a0b6-596f764dd936",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(M, axis = 0)\n",
    "sigma = np.std(M, axis=0, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee506ab7-c0b6-4e04-98e7-553de2223b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing kinship matrix.\n",
      "Kinship matrix computed.\n",
      "Kinship computation time: 0.00 seconds\n",
      "Kinship matrix normalized.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Compute Kinship Matrix using GEMMA Method\n",
    "# -----------------------------\n",
    "if benchmark:\n",
    "    start_time = time.time()\n",
    "print(\"Computing kinship matrix.\")\n",
    "K = np.dot(S, S.T) / S.shape[1]\n",
    "print(\"Kinship matrix computed.\")\n",
    "\n",
    "if benchmark:\n",
    "    kinship_time = time.time() - start_time\n",
    "    print(f\"Kinship computation time: {kinship_time:.2f} seconds\")\n",
    "\n",
    "# -----------------------------\n",
    "# Normalize Kinship Matrix\n",
    "# -----------------------------\n",
    "try:\n",
    "    K_normalized = K / np.mean(np.diagonal(K))\n",
    "    print(\"Kinship matrix normalized.\")\n",
    "except ZeroDivisionError:\n",
    "    print(\"Mean of the diagonal of the kinship matrix is zero. Cannot normalize.\")\n",
    "    exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Kinship normalization failed: {e}. Exiting.\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28d635ee-2250-4d27-a2b5-6afabb62ce31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.67821676, -0.1702268 , -0.20778734, -0.30020262],\n",
       "       [-0.1702268 ,  0.10448223,  0.07153829, -0.00579371],\n",
       "       [-0.20778734,  0.07153829,  0.11828906,  0.01795999],\n",
       "       [-0.30020262, -0.00579371,  0.01795999,  0.28803634]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5de7819-078a-4144-9a25-b40c4c2f78ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Estimate Heritability Using Limix\n",
    "# -----------------------------\n",
    "try:\n",
    "    # Define the likelihood based on phenotype type\n",
    "    # Options: \"normal\", \"bernoulli\", \"probit\", \"binomial\", \"poisson\"\n",
    "    # Adjust 'likelihood_type' as needed based on your phenotype\n",
    "    likelihood_type = \"normal\"\n",
    "\n",
    "    print(f\"Estimating heritability with likelihood: '{likelihood_type}'\")\n",
    "    h2 = limix.her.estimate(\n",
    "        y=y,\n",
    "        lik=likelihood_type,\n",
    "        K=K_normalized,\n",
    "        M=None,\n",
    "        verbose=True\n",
    "    )\n",
    "    print(f\"Estimated heritability (h2): {h2:.4f}\")\n",
    "\n",
    "    if benchmark:\n",
    "        herit_time = time.time() - start_time\n",
    "        total_time = time.time() - start_time_total\n",
    "        print(f\"Heritability estimation time: {herit_time:.2f} seconds\")\n",
    "        print(f\"Total processing time: {total_time:.2f} seconds\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Heritability estimation failed: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# -----------------------------\n",
    "# Collect and Save Results\n",
    "# -----------------------------\n",
    "print(\"Collecting results.\")\n",
    "result_entry = {\n",
    "    'V_G': h2 * (np.mean(np.diagonal(K)) * (1 - h2)),\n",
    "    'V_e': (1 - h2) * (np.mean(np.diagonal(K)) * (1 - h2)),\n",
    "    'h2': h2,\n",
    "    'n': n_samples,\n",
    "    'site': f\"chr{chromosome}_{cpg_pos}\",\n",
    "    'window_bp': w\n",
    "}\n",
    "results = [result_entry]\n",
    "\n",
    "# Collect Timing Data (if benchmarking)\n",
    "if benchmark:\n",
    "    timing_measurements = {\n",
    "        f\"chr{chromosome}_pos{cpg_pos}_window{w}\": {\n",
    "            'geno_time_sec': geno_time,\n",
    "            'kinship_time_sec': kinship_time,\n",
    "            'herit_time_sec': herit_time,\n",
    "            'total_time_sec': total_time\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Save Results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"heritability_results.csv\", index=False)\n",
    "print(\"Heritability results saved to 'heritability_results.csv'.\")\n",
    "\n",
    "# Save Timing Measurements to CSV (if benchmarking)\n",
    "if benchmark:\n",
    "    timing_df = pd.DataFrame.from_dict(timing_measurements, orient='index')\n",
    "    timing_df.reset_index(inplace=True)\n",
    "    timing_df.rename(columns={'index': 'ID'}, inplace=True)\n",
    "    timing_df.to_csv(\"timing_measurements.csv\", index=False)\n",
    "    print(\"Timing measurements saved to 'timing_measurements.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77592e7c-1fc7-46d8-b1eb-81ed6e22bed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b99b0c-5000-441f-826b-956354378da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4055f4-6f5c-43f2-95f0-6ed783a7112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.chdir(output_dir)\n",
    "\n",
    "# -----------------------------\n",
    "# Read the Metadata DataFrame\n",
    "# -----------------------------\n",
    "df = pd.read_csv(df_csv_path)\n",
    "\n",
    "# Initialize Results Storage\n",
    "results = []\n",
    "timing_measurements = {}\n",
    "\n",
    "# -----------------------------\n",
    "# Function to Normalize Kinship Matrix\n",
    "# -----------------------------\n",
    "def normalize_kinship(K):\n",
    "    \"\"\"Normalize the kinship matrix as required by Limix.\"\"\"\n",
    "    mean_diag = np.mean(np.diagonal(K))\n",
    "    if mean_diag == 0:\n",
    "        raise ValueError(\"Mean of the diagonal of the kinship matrix is zero.\")\n",
    "    return K / mean_diag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7540c32-5389-43bf-9dea-68febf6846de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "os.chdir(outdir)\n",
    "\n",
    "# Read the data frame containing paths to SNP and methylation data\n",
    "df = pd.read_csv(df_csv)\n",
    "\n",
    "# Processing the first row as per df_row in R script\n",
    "df_row = 0  # Adjust as needed\n",
    "\n",
    "# Extract paths from the data frame\n",
    "gwas_dir = os.path.dirname(df.loc[df_row, 'SNP_data'])\n",
    "methylation_file = df.loc[df_row, 'modified_methylation_data']\n",
    "\n",
    "methylation_file = methylation_file.replace(\"/dcs04/lieber/statsgen/shizhong/michael/mwas/pheno/\", \"/dcs04/lieber/statsgen/mnagle/mwas/pheno/\")\n",
    "\n",
    "methylation_file = methylation_file.replace(\"rda\", \"csv\")\n",
    "methylation_file = methylation_file.replace(\"rds\", \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108bab98-a49a-4b15-93d8-97b652d9c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "methylation_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9fe719-aa22-495d-bd67-fd994bed0f22",
   "metadata": {},
   "source": [
    "## Re-run once finihsed reprocessing csv formatted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0cc958-ccd4-4040-920e-c5396bc42e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_start = chunk1\n",
    "chunk_end = chunk2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88fe9c7-2a53-4683-a5da-f7a2b6c7c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromosome = df.loc[df_row, 'Chr']\n",
    "window_sizes = wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f90e4c-f01d-48c5-b539-df06909b551c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, (cpg_col, cpg_pos) in enumerate(zip(selected_cpg_cols, selected_cpg_positions), start=chunk_start):\n",
    "    print(f\"  Processing CpG site {idx} at position {cpg_pos}\")\n",
    "\n",
    "    # Extract methylation levels for the current CpG site\n",
    "    pheno_df = methylation_df[['sample_id', cpg_col]].dropna()\n",
    "    y = pheno_df[cpg_col].values\n",
    "    sample_ids = pheno_df['sample_id'].values\n",
    "    n_samples = len(sample_ids)\n",
    "\n",
    "    if n_samples == 0:\n",
    "        print(\"    No samples with non-missing methylation data. Skipping this CpG site.\")\n",
    "        continue\n",
    "\n",
    "    # -----------------------------\n",
    "    # Loop Over Window Sizes\n",
    "    # -----------------------------\n",
    "    for w in window_sizes:\n",
    "        print(f\"    Window size: {w} bp\")\n",
    "\n",
    "        if benchmark:\n",
    "            start_time_total = time.time()\n",
    "\n",
    "        # Define genomic window\n",
    "        p1 = max(cpg_pos - w, 0)\n",
    "        p2 = cpg_pos + w\n",
    "\n",
    "        # -----------------------------\n",
    "        # Load Genotype Data for the Specified Chromosome\n",
    "        # -----------------------------\n",
    "        pgen_prefix = os.path.join(gwas_dir, f\"libd_chr{chromosome}\")\n",
    "        pgen_file = f\"{pgen_prefix}.pgen\"\n",
    "        pvar_file = f\"{pgen_prefix}.pvar\"\n",
    "        psam_file = f\"{pgen_prefix}.psam\"\n",
    "\n",
    "        # Check if all necessary PLINK 2 files exist\n",
    "        if not all(os.path.exists(f) for f in [pgen_file, pvar_file, psam_file]):\n",
    "            print(\"      One or more PLINK 2 files are missing. Skipping this window.\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Read Sample IDs from .psam File\n",
    "        # -----------------------------\n",
    "        try:\n",
    "            psam_df = pd.read_csv(psam_file, sep='\\t')\n",
    "            if '#IID' not in psam_df.columns:\n",
    "                print(f\"      '#IID' column not found in .psam file '{psam_file}'. Skipping this window.\")\n",
    "                continue\n",
    "            geno_sample_ids = psam_df['#IID'].astype(str).values\n",
    "        except Exception as e:\n",
    "            print(f\"      Error reading .psam file '{psam_file}': {e}\")\n",
    "            continue\n",
    "\n",
    "        # Create a mapping from sample ID to index in genotype data\n",
    "        sample_id_to_index = {sid: idx for idx, sid in enumerate(geno_sample_ids)}\n",
    "\n",
    "        # Get genotype indices for samples present in methylation data\n",
    "        geno_indices = [sample_id_to_index[sid] for sid in sample_ids if sid in sample_id_to_index]\n",
    "\n",
    "        if not geno_indices:\n",
    "            print(\"      No matching samples between genotype and methylation data. Skipping this window.\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Read SNP Positions from .pvar File\n",
    "        # -----------------------------\n",
    "        try:\n",
    "            pvar_df = pd.read_csv(pvar_file, sep='\\t', comment='#',\n",
    "                                  names=['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT'])\n",
    "        except Exception as e:\n",
    "            print(f\"      Error reading .pvar file '{pvar_file}': {e}\")\n",
    "            continue\n",
    "\n",
    "        # Subset SNPs within the genomic window\n",
    "        snps_in_window = pvar_df[(pvar_df['POS'] >= p1) & (pvar_df['POS'] <= p2)]\n",
    "\n",
    "        if snps_in_window.empty:\n",
    "            print(\"      No SNPs found within this window. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Get variant indices (0-based)\n",
    "        variant_indices = snps_in_window.index.values\n",
    "\n",
    "        # -----------------------------\n",
    "        # Read Genotype Data Using PgenReader\n",
    "        # -----------------------------\n",
    "        try:\n",
    "            # Initialize PgenReader with sample_subset\n",
    "            # PgenReader expects the filename as bytes\n",
    "            pgr = PgenReader(pgen_file.encode('utf-8'), sample_subset=np.array(geno_indices, dtype=np.uint32))\n",
    "\n",
    "            # Allocate buffer: rows=variants, cols=samples\n",
    "            geno_buffer = np.empty((len(variant_indices), n_samples), dtype=np.int32)\n",
    "\n",
    "            # Read each variant and populate the buffer\n",
    "            for var_idx, variant_idx in enumerate(variant_indices):\n",
    "                # Read genotype for the current variant\n",
    "                # allele_idx=1 corresponds to the alternate allele count\n",
    "                pgr.read(variant_idx, geno_buffer[var_idx, :], allele_idx=1)\n",
    "\n",
    "            # -----------------------------\n",
    "            # Benchmarking: Genotype Reading Time\n",
    "            # -----------------------------\n",
    "            if benchmark:\n",
    "                geno_time = time.time() - start_time_total\n",
    "                start_time = time.time()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"      Error reading genotype data: {e}\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Check for Missing Data and Impute\n",
    "        # -----------------------------\n",
    "        if np.any(geno_buffer == -9):\n",
    "            print(\"      Missing genotype data detected. Imputing missing values with mean genotype.\")\n",
    "            # Replace missing genotypes (-9) with the mean genotype for each SNP\n",
    "            for var in range(geno_buffer.shape[0]):\n",
    "                missing = geno_buffer[var, :] == -9\n",
    "                if np.any(missing):\n",
    "                    non_missing = geno_buffer[var, :] != -9\n",
    "                    if np.any(non_missing):\n",
    "                        mean_geno = np.mean(geno_buffer[var, non_missing])\n",
    "                        geno_buffer[var, missing] = mean_geno\n",
    "                    else:\n",
    "                        # If all genotypes are missing, impute with 0\n",
    "                        geno_buffer[var, missing] = 0\n",
    "\n",
    "        # -----------------------------\n",
    "        # Standardize Genotypes\n",
    "        # -----------------------------\n",
    "        M = geno_buffer.astype(float)\n",
    "        mu = np.mean(M, axis=0)\n",
    "        sigma = np.std(M, axis=0, ddof=1)\n",
    "        sigma[sigma == 0] = 1  # Avoid division by zero\n",
    "        S = (M - mu) / sigma\n",
    "        S = np.nan_to_num(S)\n",
    "\n",
    "        # Compute kinship matrix using GEMMA method\n",
    "        K = np.dot(S, S.T) / S.shape[1]\n",
    "\n",
    "        if benchmark:\n",
    "            kinship_time = time.time() - start_time\n",
    "            start_time = time.time()\n",
    "\n",
    "        # -----------------------------\n",
    "        # Normalize Kinship Matrix\n",
    "        # -----------------------------\n",
    "        try:\n",
    "            K_normalized = normalize_kinship(K)\n",
    "        except ValueError as e:\n",
    "            print(f\"      Kinship normalization failed: {e}. Skipping this window.\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Estimate Heritability Using Limix\n",
    "        # -----------------------------\n",
    "        try:\n",
    "            # Define the likelihood based on phenotype type\n",
    "            # Adjust 'likelihood_type' as needed based on your phenotype\n",
    "            # Options: \"normal\", \"bernoulli\", \"probit\", \"binomial\", \"poisson\"\n",
    "            # For this example, we'll assume a \"normal\" phenotype\n",
    "            likelihood_type = \"normal\"\n",
    "\n",
    "            # Estimate heritability\n",
    "            h2 = limix.her.estimate(\n",
    "                y=y,\n",
    "                lik=likelihood_type,\n",
    "                K=K_normalized,\n",
    "                M=None,\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            if benchmark:\n",
    "                herit_time = time.time() - start_time\n",
    "                total_time = time.time() - start_time_total\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"      Heritability estimation failed: {e}\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Collect Results\n",
    "        # -----------------------------\n",
    "        result_entry = {\n",
    "            'V_G': h2 * (np.mean(np.diagonal(K)) * (1 - h2)),\n",
    "            'V_e': (1 - h2) * (np.mean(np.diagonal(K)) * (1 - h2)),\n",
    "            'h2': h2,\n",
    "            'n': n_samples,\n",
    "            'site': f\"chr{chromosome}_{cpg_pos}\",\n",
    "            'window_bp': w\n",
    "        }\n",
    "        results.append(result_entry)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Collect Timing Data (if benchmarking)\n",
    "        # -----------------------------\n",
    "        if benchmark:\n",
    "            timing_entry = {\n",
    "                'geno_time_sec': geno_time,\n",
    "                'kinship_time_sec': kinship_time,\n",
    "                'herit_time_sec': herit_time,\n",
    "                'total_time_sec': total_time\n",
    "            }\n",
    "            timing_measurements[f\"chr{chromosome}_pos{cpg_pos}_window{w}\"] = timing_entry\n",
    "\n",
    "        print(f\"      Completed CpG site {idx}, window {w} bp\")\n",
    "\n",
    "# -----------------------------\n",
    "# Save Results to CSV\n",
    "# -----------------------------\n",
    "if results:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(\"heritability_results.csv\", index=False)\n",
    "    print(\"\\nHeritability results saved to 'heritability_results.csv'.\")\n",
    "else:\n",
    "    print(\"\\nNo heritability results to save.\")\n",
    "\n",
    "if benchmark and timing_measurements:\n",
    "    timing_df = pd.DataFrame.from_dict(timing_measurements, orient='index')\n",
    "    timing_df.reset_index(inplace=True)\n",
    "    timing_df.rename(columns={'index': 'ID'}, inplace=True)\n",
    "    timing_df.to_csv(\"timing_measurements.csv\", index=False)\n",
    "    print(\"Timing measurements saved to 'timing_measurements.csv'.\")\n",
    "elif benchmark:\n",
    "    print(\"No timing measurements to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede65f58-6eda-45a7-afc0-ced2e9d55537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PgenReader with sample_subset\n",
    "pgr = PgenReader(pgen_file, sample_subset=np.array(geno_indices, dtype=np.uint32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e0cff-b518-45b1-a169-9c98375bb45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgen_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a3efc3-a0a6-4e5a-8aa0-6f669af63e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the range of variants\n",
    "# Assuming variants are sorted by position; hence, read them sequentially\n",
    "# Allocate buffer: rows=variants, cols=samples\n",
    "geno_buffer = np.empty((len(variant_indices), n_samples), dtype=np.int32)\n",
    "\n",
    "# Read each variant and populate the buffer\n",
    "for var_idx, geno_idx in enumerate(variant_indices):\n",
    "    # Read genotype for the current variant\n",
    "    # Variants are 0-based; ensure correct indexing\n",
    "    pgr.read(var_idx, geno_buffer[var_idx, :], allele_idx=1)\n",
    "\n",
    "# -----------------------------\n",
    "# Benchmarking: Genotype Reading Time\n",
    "# -----------------------------\n",
    "if benchmark:\n",
    "    geno_time = time.time() - start_time_total\n",
    "    start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cc9deb-a6e7-4f12-a2ae-84b4ceff5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last version from o1-preview, gave error:\n",
    "# ---------------------------------------------------------------------------\n",
    "# TypeError                                 Traceback (most recent call last)\n",
    "# Cell In[5], line 83\n",
    "#      80     start_time = time.time()\n",
    "#      82 # Initialize PgenReader\n",
    "# ---> 83 pgr = PgenReader(pgen_file, sample_subset=geno_indices, variant_subset=snp_indices)\n",
    "#      85 # Read genotype data\n",
    "#      86 M = np.empty((len(geno_indices), len(snp_indices)), dtype=np.float32)\n",
    "\n",
    "# File src/pgenlib/pgenlib.pyx:400, in pgenlib.PgenReader.__cinit__()\n",
    "\n",
    "# TypeError: __cinit__() got an unexpected keyword argument 'variant_subset'\n",
    "\n",
    "# chr_number = df.loc[df_row, 'Chr']  # Assuming 'Chr' column has the chromosome number\n",
    "\n",
    "# # Load methylation data\n",
    "# # Methylation data has CpG positions as columns and samples as rows\n",
    "# methylation_df = pd.read_csv(methylation_file)\n",
    "\n",
    "# # 'sample_id' is the first column\n",
    "# # Extract CpG columns (all columns except 'sample_id')\n",
    "# CpG_columns = methylation_df.columns.drop('sample_id')\n",
    "# CpG_positions = [int(col.split('_')[1]) for col in CpG_columns]  # Extract numeric positions\n",
    "\n",
    "# # Create a mapping from column names to positions\n",
    "# CpG_col_to_pos = dict(zip(CpG_columns, CpG_positions))\n",
    "\n",
    "# # Select the CpG positions for the specified chunk\n",
    "# CpG_columns_chunk = CpG_columns[chunk1 - 1:chunk2]\n",
    "# CpG_positions_chunk = [CpG_col_to_pos[col] for col in CpG_columns_chunk]\n",
    "\n",
    "# # Initialize results storage\n",
    "# results = []\n",
    "# time_measurements = {}\n",
    "\n",
    "# # Loop over CpG sites\n",
    "# for idx, (CpG_col, CpG_position) in enumerate(zip(CpG_columns_chunk, CpG_positions_chunk), start=chunk1):\n",
    "#     print(f\"Processing CpG site {idx} at position {CpG_position} on chromosome {chr_number}\")\n",
    "    \n",
    "#     # Extract methylation levels for the current CpG site\n",
    "#     pheno_df = methylation_df[['sample_id', CpG_col]].dropna()\n",
    "#     y = pheno_df[CpG_col].values\n",
    "#     sample_ids = pheno_df['sample_id'].astype(str).values\n",
    "#     n_samples = len(sample_ids)\n",
    "    \n",
    "#     # Loop over window sizes\n",
    "#     for w in wind:\n",
    "#         print(f\"Window size: {w} bp\")\n",
    "#         if benchmark:\n",
    "#             start_time_total = time.time()\n",
    "        \n",
    "#         # Define genomic window\n",
    "#         p1 = max(CpG_position - w, 0)\n",
    "#         p2 = CpG_position + w\n",
    "\n",
    "#         # Load genotype data for the specified chromosome\n",
    "#         pgen_prefix = os.path.join(gwas_dir, f\"libd_chr{chr_number}\")\n",
    "#         pgen_file = f\"{pgen_prefix}.pgen\"\n",
    "#         pvar_file = f\"{pgen_prefix}.pvar\"\n",
    "#         psam_file = f\"{pgen_prefix}.psam\"\n",
    "\n",
    "#         # Check if files exist\n",
    "#         if not all(os.path.exists(f) for f in [pgen_file, pvar_file, psam_file]):\n",
    "#             print(\"One or more PLINK 2 files are missing. Skipping.\")\n",
    "#             continue\n",
    "\n",
    "#         # Read sample IDs from .psam file\n",
    "#         psam_df = pd.read_csv(psam_file, sep='\\t')\n",
    "#         geno_sample_ids = psam_df['#IID'].astype(str).values\n",
    "\n",
    "#         # Map sample IDs to indices\n",
    "#         sample_id_to_index = {sid: idx for idx, sid in enumerate(geno_sample_ids)}\n",
    "#         geno_indices = [sample_id_to_index.get(sid) for sid in sample_ids if sid in sample_id_to_index]\n",
    "\n",
    "#         if not geno_indices:\n",
    "#             print(\"No matching samples between genotype and methylation data. Skipping.\")\n",
    "#             continue\n",
    "\n",
    "#         # Read SNP positions from .pvar file\n",
    "#         pvar_df = pd.read_csv(pvar_file, sep='\\t', comment='#',\n",
    "#                               names=['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT'])\n",
    "#         # Subset SNPs within the window\n",
    "#         snps_in_window = pvar_df[(pvar_df['POS'] >= p1) & (pvar_df['POS'] <= p2)]\n",
    "\n",
    "#         if snps_in_window.empty:\n",
    "#             print(\"No SNPs in this window. Skipping.\")\n",
    "#             continue\n",
    "\n",
    "#         # Get indices of SNPs in the window\n",
    "#         snp_indices = snps_in_window.index.values\n",
    "\n",
    "#         if benchmark:\n",
    "#             start_time = time.time()\n",
    "\n",
    "#         # Initialize PgenReader\n",
    "#         pgr = PgenReader(pgen_file, sample_subset=geno_indices, variant_subset=snp_indices)\n",
    "\n",
    "#         # Read genotype data\n",
    "#         M = np.empty((len(geno_indices), len(snp_indices)), dtype=np.float32)\n",
    "#         pgr.read(M)\n",
    "\n",
    "#         if benchmark:\n",
    "#             geno_time = time.time() - start_time\n",
    "#             start_time = time.time()\n",
    "\n",
    "#         # Check if sample sizes match\n",
    "#         if M.shape[0] != y.shape[0]:\n",
    "#             print(\"Mismatch in sample sizes after subsetting. Skipping.\")\n",
    "#             continue\n",
    "\n",
    "#         # Standardize genotypes\n",
    "#         n_samples, n_snps = M.shape\n",
    "#         mu = np.mean(M, axis=0)\n",
    "#         std = np.std(M, axis=0, ddof=1)\n",
    "#         std[std == 0] = 1  # Avoid division by zero\n",
    "#         S = (M - mu) / std\n",
    "#         S = np.nan_to_num(S)\n",
    "#         K = np.dot(S, S.T) / n_snps  # Kinship matrix\n",
    "\n",
    "#         if benchmark:\n",
    "#             kinship_time = time.time() - start_time\n",
    "#             start_time = time.time()\n",
    "\n",
    "#         # Estimate heritability using limix\n",
    "#         try:\n",
    "#             # Construct the linear mixed model\n",
    "#             y_centered = y - np.mean(y)\n",
    "#             covar = np.ones((n_samples, 1))  # Intercept\n",
    "\n",
    "#             # Use limix LinearMixedModel\n",
    "#             from limix.qtl import scan\n",
    "\n",
    "#             # Reshape y and covariates\n",
    "#             y_centered = y_centered.reshape(-1, 1)\n",
    "#             covar = covar.reshape(-1, 1)\n",
    "\n",
    "#             # Perform GWAS scan (single-variant association test) to estimate variance components\n",
    "#             # Here, we can use the variance components from the null model\n",
    "#             result = scan(y=y_centered, M=None, K=K, X=covar, verbose=False)\n",
    "\n",
    "#             # Extract variance components\n",
    "#             sigma_g2 = result.variance_components['V(K)'][0]\n",
    "#             sigma_e2 = result.variance_components['V(I)'][0]\n",
    "#             h2 = sigma_g2 / (sigma_g2 + sigma_e2)\n",
    "\n",
    "#             if benchmark:\n",
    "#                 herit_time = time.time() - start_time\n",
    "#                 total_time = time.time() - start_time_total\n",
    "#         except Exception as e:\n",
    "#             print(f\"Heritability estimation failed: {e}\")\n",
    "#             continue\n",
    "\n",
    "#         # Collect results\n",
    "#         temp2 = {\n",
    "#             'V_G': sigma_g2,\n",
    "#             'V_e': sigma_e2,\n",
    "#             'V_G_Vp': h2,\n",
    "#             'n': n_samples,\n",
    "#             'site': f\"chr{chr_number}_{CpG_position}\",\n",
    "#             'wind': w\n",
    "#         }\n",
    "#         results.append(temp2)\n",
    "\n",
    "#         # Collect timing data if benchmarking\n",
    "#         if benchmark:\n",
    "#             key = f\"chr{chr_number}_pos{CpG_position}_wind{w}\"\n",
    "#             time_measurements[key] = {\n",
    "#                 'geno_time': geno_time,\n",
    "#                 'kinship_time': kinship_time,\n",
    "#                 'herit_time': herit_time,\n",
    "#                 'total_time': total_time\n",
    "#             }\n",
    "\n",
    "#         print(f\"Completed CpG site {idx}, window {w}\")\n",
    "\n",
    "#     print(\"\\n\")\n",
    "\n",
    "# # Convert results to a DataFrame and save\n",
    "# results_df = pd.DataFrame(results)\n",
    "# results_df.to_csv(\"heritability_results.csv\", index=False)\n",
    "\n",
    "# # Save timing measurements if benchmarking\n",
    "# if benchmark:\n",
    "#     timing_df = pd.DataFrame.from_dict(time_measurements, orient='index')\n",
    "#     timing_df.reset_index(inplace=True)\n",
    "#     timing_df.rename(columns={'index': 'ID'}, inplace=True)\n",
    "#     timing_df.to_csv(\"timing_measurements.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e133c6-3f37-4a67-9a03-9295160b592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "?PgenReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0d4588-971b-4c43-9139-5067987ec7bf",
   "metadata": {},
   "source": [
    "## Correct structure of methylation df!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea8add-75fb-4e00-baf9-5cd9c5cde4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92263c9-9eae-4f24-9edd-2017cfe5d11c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

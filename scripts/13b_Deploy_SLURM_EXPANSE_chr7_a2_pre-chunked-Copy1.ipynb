{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb72484-0e2e-4d13-bda9-58fe13e8ae34",
   "metadata": {},
   "source": [
    "# Prep SLURM commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16eddb68-67bf-48d8-9343-a7e48c69b312",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/expanse/lustre/projects/jhu152/naglemi/mwas/CpGWAS/scripts'"
      ],
      "text/latex": [
       "'/expanse/lustre/projects/jhu152/naglemi/mwas/CpGWAS/scripts'"
      ],
      "text/markdown": [
       "'/expanse/lustre/projects/jhu152/naglemi/mwas/CpGWAS/scripts'"
      ],
      "text/plain": [
       "[1] \"/expanse/lustre/projects/jhu152/naglemi/mwas/CpGWAS/scripts\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b30812-6ff8-4543-9515-f482ba6fa246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(data.table)\n",
    "library(stringr)\n",
    "\n",
    "setwd(\"../\")\n",
    "\n",
    "#' Generate Chunk Ranges with Fixed Number of Chunks\n",
    "#'\n",
    "#' This function divides a range into a specified number of chunks, with each chunk\n",
    "#' having approximately the same size.\n",
    "#'\n",
    "#' @param start The starting point of the range to be divided.\n",
    "#' @param end The ending point of the range to be divided.\n",
    "#' @param num_chunks The fixed number of chunks to divide the range into.\n",
    "#'\n",
    "#' @return A matrix where each row represents a chunk, with the first column being\n",
    "#'         the start of the chunk and the second column being the end of the chunk.\n",
    "#' @examples\n",
    "#' chunk_fixed_n(1, 100, 5)\n",
    "#' @export\n",
    "chunk_fixed_n <- function(start, end, num_chunks) {\n",
    "  chunk_size <- ceiling((end - start + 1) / num_chunks)\n",
    "  chunk_ranges <- sapply(1:num_chunks, function(i) {\n",
    "    chunk_start <- start + (i - 1) * chunk_size\n",
    "    chunk_end <- min(chunk_start + chunk_size - 1, end)\n",
    "    c(chunk_start, chunk_end)\n",
    "  })\n",
    "  return(chunk_ranges)\n",
    "}\n",
    "\n",
    "#' Generate Chunk Ranges with Fixed Chunk Size\n",
    "#'\n",
    "#' This function divides a range into chunks up to a given maximum size, dynamically\n",
    "#' determining the number of chunks based on the range and maximum chunk size.\n",
    "#'\n",
    "#' @param start The starting point of the range to be divided.\n",
    "#' @param end The ending point of the range to be divided.\n",
    "#' @param max_chunk_size The maximum size that each chunk can have.\n",
    "#'\n",
    "#' @return A matrix where each row represents a chunk, with the first column being\n",
    "#'         the start of the chunk and the second column being the end of the chunk.\n",
    "#'         The last chunk may be smaller than `max_chunk_size` to fit the range.\n",
    "#' @examples\n",
    "#' chunk_fixed_size(1, 100, 20)\n",
    "#' @export\n",
    "chunk_fixed_size <- function(start, end, max_chunk_size) {\n",
    "  if (length(start) > 1 || length(end) > 1) {\n",
    "    stop(\"start and end must be single values\")\n",
    "  }\n",
    "  if (start > end || max_chunk_size <= 0) {\n",
    "    stop(\"Invalid arguments: ensure start <= end and max_chunk_size > 0\")\n",
    "  }\n",
    "  \n",
    "  num_chunks <- ceiling((end - start + 1) / max_chunk_size)\n",
    "  chunk_ranges <- matrix(nrow = num_chunks, ncol = 2)\n",
    "  \n",
    "  for (i in 1:num_chunks) {\n",
    "    chunk_start <- start + (i - 1) * max_chunk_size\n",
    "    chunk_end <- min(chunk_start + max_chunk_size - 1, end)\n",
    "    chunk_ranges[i, ] <- c(chunk_start, chunk_end)\n",
    "  }\n",
    "  \n",
    "  return(t(chunk_ranges))\n",
    "}\n",
    "\n",
    "generate_slurm_script <- function(args, tag_pt1, tag_pt2, partition, acct, mem_per_cpu = \"2G\", cluster_specific_parameters = TRUE, nodes = NULL, ntasks_per_node = NULL, time = \"24:00:00\", module_load_conda = FALSE) {\n",
    "  cpus_per_task <- if (is.null(args$num_cores) || args$num_cores == \"all\") {\n",
    "    \"#SBATCH --exclusive\\n\"\n",
    "  } else {\n",
    "    paste0(\"#SBATCH --cpus-per-task=\", args$num_cores, \"\\n\")\n",
    "  }\n",
    "\n",
    "  # Always set mem_per_cpu flag, even in exclusive mode\n",
    "  mem_allocation <- paste0(\"#SBATCH --mem-per-cpu=\", mem_per_cpu, \"\\n\")\n",
    "\n",
    "  args_string <- paste(\"--\", names(args), \"=\", args, sep = \"\", collapse = \" \")\n",
    "  args_string <- paste(args_string, \" --tag=\", tag_pt1, \"-\", tag_pt2, sep = \"\")\n",
    "\n",
    "  slurm_script <- paste0(\n",
    "    \"#!/bin/bash\\n\",\n",
    "    if (cluster_specific_parameters) paste0(\n",
    "      \"#SBATCH --partition=\", partition, \"\\n\",\n",
    "      \"#SBATCH -A \", acct, \"\\n\"\n",
    "    ),\n",
    "    if (!is.null(nodes) && !is.null(ntasks_per_node)) paste0(\n",
    "      \"#SBATCH --nodes=\", nodes, \"\\n\",\n",
    "      \"#SBATCH --ntasks-per-node=\", ntasks_per_node, \"\\n\"\n",
    "    ),\n",
    "    cpus_per_task,\n",
    "    mem_allocation,\n",
    "    \"#SBATCH --output=slurm_output_\", tag_pt1, \"-\", tag_pt2, \".out\\n\",\n",
    "    \"#SBATCH --job-name=\", tag_pt1, \"-\", tag_pt2, \"\\n\",\n",
    "    \"#SBATCH --time=\", time, \"\\n\",\n",
    "    if (module_load_conda) \"module load conda\\n\",\n",
    "    \"conda activate mwas\\n\",\n",
    "    \"echo 'Executing Rscript with arguments: Rscript scripts/CLI.R \", args_string, \"'\\n\",\n",
    "    \"Rscript scripts/CLI.R \", args_string, \"\\n\"\n",
    "  )\n",
    "\n",
    "  return(list(script = slurm_script, path = paste0(\"slurm_scripts/\", tag_pt1, \"-\", tag_pt2, \".sh\")))\n",
    "}\n",
    "\n",
    "# Define a function to run sacct and retrieve job names and statuses\n",
    "get_job_info <- function() {\n",
    "  # Use system2 to call sacct and capture output\n",
    "  output <- system2(\"sacct\", args = c(\"--format=JobName%200,State\", \"--noheader\"), stdout = TRUE)\n",
    "  \n",
    "  # Split output into lines and then into columns\n",
    "  job_data <- strsplit(output, \"\\n\")\n",
    "  job_info <- do.call(rbind, lapply(job_data, function(x) strsplit(x, \"\\\\s+\")))\n",
    "  \n",
    "  # Convert to data frame and name columns\n",
    "  job_df <- as.data.frame(do.call(rbind, job_info), stringsAsFactors = FALSE)[, 2:3]\n",
    "  names(job_df) <- c(\"JobName\", \"State\")\n",
    "  \n",
    "  # Return the data frame\n",
    "  return(job_df)\n",
    "}\n",
    "\n",
    "# Cluster-specific parameters\n",
    "cluster_specific_parameters <- TRUE # Example condition\n",
    "acct <- \"jhu152\"\n",
    "time <- \"48:00:00\"\n",
    "partition <- \"shared\"\n",
    "\n",
    "module_load_conda <- FALSE\n",
    "\n",
    "nodes <- 1\n",
    "ntasks_per_node <- 1\n",
    "\n",
    "# Overwrite flag (set by user)\n",
    "overwrite <- FALSE\n",
    "\n",
    "# chunk_ranges <- chunk_fixed_size(files$first_meth_index_with_SNP_coverage[i],\n",
    "#                                  files$last_meth_index_with_SNP_coverage[i],\n",
    "#                                  1000)\n",
    "                         \n",
    "\n",
    "# chunk_ranges <- chunk_ranges[1:2,1:2]\n",
    "\n",
    "#chunk_ranges <- chunk_fixed_n(1, 10000, 5)\n",
    "\n",
    "getwd()\n",
    "\n",
    "matched_df <- fread(\"../CpGWAS/scripts/09.5-OUT_matched_SNP_meth_cov_chunked_JHPCE.csv\")\n",
    "\n",
    "matched_df <- matched_df[order(matched_df$SNP_data), ]\n",
    "\n",
    "dim(matched_df)\n",
    "\n",
    "dim(matched_df)\n",
    "\n",
    "matched_df$SNP_data <- gsub(\"/dcs04/lieber/statsgen/shizhong/michael/mwas/gwas/\", \"/expanse/lustre/projects/jhu152/naglemi/mwas/gwas/\", matched_df$SNP_data)\n",
    "matched_df$methylation_data <- gsub(\"/dcs04/lieber/statsgen/shizhong/michael/mwas/pheno/\", \"/expanse/lustre/projects/jhu152/naglemi/mwas/pheno/\", matched_df$methylation_data)\n",
    "matched_df$cov_file <- gsub(\"/dcs04/lieber/statsgen/mnagle/mwas/full_covariates/\", \"/expanse/lustre/projects/jhu152/naglemi/mwas/full_covariates/\", matched_df$cov_file)\n",
    "\n",
    "matched_df$modified_methylation_data <- gsub(\"/dcs04/lieber/statsgen/mnagle/\", \"/expanse/lustre/projects/jhu152/naglemi/\", matched_df$modified_methylation_data)\n",
    "\n",
    "for(i in 1:nrow(matched_df)){\n",
    "    \n",
    "    \n",
    "    region <- str_split_fixed(\n",
    "    str_split_fixed(matched_df$methylation_data[i], \"pheno/\", 2)[, 2],\n",
    "    \"/out\", 2)[, 1]\n",
    "    outdir <- paste0(\"./output_EXPANSE_a2_\", region, \"/\")\n",
    "    if(!dir.exists(outdir)) dir.create(outdir)\n",
    "\n",
    "    chunk_size <- matched_df$chunk_end[i] - matched_df$chunk_start[i] + 1\n",
    "    \n",
    "    # Constant Arguments Setup\n",
    "    constant_args_df <- data.frame(\n",
    "      outdir = outdir,\n",
    "      snp_data_path = matched_df$SNP_data[i],\n",
    "      methylation_data_path = matched_df$methylation_data[i],\n",
    "      cov = matched_df$cov_file[i],\n",
    "      verbose = TRUE,\n",
    "      lambda_choice = \"1se\",\n",
    "      alphas = 0.5,\n",
    "      allow_inefficient_parallelization = FALSE,\n",
    "      n_fold = 5,\n",
    "      window_sizes = \"10000\",\n",
    "      #window_sizes = \"500000\",\n",
    "      save_evaluation_results_each_fold = FALSE,\n",
    "      save_glmnet_object = FALSE,\n",
    "      omit_folds_with_na_r = TRUE,\n",
    "      methInput_rds_path = matched_df$modified_methylation_data[i]\n",
    "    )\n",
    "    \n",
    "    # Varying parameters\n",
    "    cv_eval_modes <- c(\"dynamic\")\n",
    "    cores_per_alphas <- c(\"all\") #NA)  # Include NA to signify the default value should be used\n",
    "    num_cores_options <- c(1)\n",
    "    \n",
    "    #for (chunk_range in 2){\n",
    "    constant_args_df$chunk1 <- 1\n",
    "    constant_args_df$chunk2 <- chunk_size\n",
    "    # Loop through each combination\n",
    "    for (cv_eval_mode in cv_eval_modes) {\n",
    "      for (cores_per_alpha in cores_per_alphas) {\n",
    "        for (num_cores in num_cores_options) {\n",
    "          # Update constant_args_df for the current combination\n",
    "          constant_args_df$cv_eval_mode <- cv_eval_mode\n",
    "          constant_args_df$num_cores <- num_cores\n",
    "          if (!is.na(cores_per_alpha)) {\n",
    "            constant_args_df$cores_per_alpha <- cores_per_alpha\n",
    "          } else {\n",
    "            constant_args_df$cores_per_alpha <- NULL\n",
    "          }\n",
    "\n",
    "          # Generate tags\n",
    "          snp_base <- tools::file_path_sans_ext(basename(constant_args_df$snp_data_path))\n",
    "          meth_base <- tools::file_path_sans_ext(basename(constant_args_df$methylation_data_path))\n",
    "          datetime_str <- format(Sys.time(), \"%Y%m%d-%H%M%S\")\n",
    "          tag_pt1 <- paste(snp_base, meth_base, format(matched_df$chunk_start[i], scientific = FALSE), format(matched_df$chunk_end[i], scientific = FALSE), cv_eval_mode, paste0(num_cores, \"corestotal\"), ifelse(is.na(cores_per_alpha), \"defaultcore\", paste0(cores_per_alpha, \"corepera\")), sep = \"-\")\n",
    "          tag_pt2 <- datetime_str\n",
    "            \n",
    "          all_files_in_directory <- list.files(path = constant_args_df$outdir, full.names = TRUE)\n",
    "          #print(paste(\"All files in directory: \", constant_args_df$outdir))\n",
    "          #print(all_files_in_directory)\n",
    "\n",
    "          # Now check with the specific pattern\n",
    "          #existing_files_pattern <- paste0(\"^\", tag_pt1, \".*\\\\.rds$\")\n",
    "          existing_files <- list.files(path = constant_args_df$outdir, pattern = tag_pt1, full.names = TRUE)\n",
    "          existing_files <- existing_files[grepl(\"rds\", existing_files)]\n",
    "            \n",
    "          # Diagnostic print statements for troubleshooting\n",
    "          #print(paste(\"Checking for files in: \", constant_args_df$outdir))\n",
    "          #print(paste(\"Using pattern: \", tag_pt1))\n",
    "          #print(\"Found files with specific pattern: \")\n",
    "          #print(existing_files)\n",
    "          \n",
    "          if (!overwrite && length(existing_files) > 0) {\n",
    "            #message(\"File with tag \", tag_pt1, \" already exists. Skipping...\")\n",
    "            next\n",
    "          }\n",
    "            \n",
    "          print(i)\n",
    "            \n",
    "          # # Now check with the specific pattern\n",
    "          # #existing_files_pattern <- paste0(\"^\", tag_pt1, \".*\\\\.rds$\")\n",
    "          # existing_jobs <- get_job_info()$JobName\n",
    "          # existing_jobs <- existing_jobs[grepl(tag_pt1, existing_jobs)]\n",
    "            \n",
    "          # # Diagnostic print statements for troubleshooting\n",
    "          # print(paste(\"Checking for jobs on sacct\"))\n",
    "          # print(paste(\"Using pattern: \", tag_pt1))\n",
    "          # print(\"Found jobs with specific pattern: \")\n",
    "          # print(existing_jobs)\n",
    "          \n",
    "          # if (!overwrite && length(existing_jobs) > 0) {\n",
    "          #   message(\"Job with tag \", tag_pt1, \" already exists. Skipping...\")\n",
    "          #   next\n",
    "          # }\n",
    "\n",
    "\n",
    "          # Generate and print SLURM script\n",
    "          script_info <- generate_slurm_script(args = constant_args_df,\n",
    "                                               tag_pt1 = tag_pt1,\n",
    "                                               tag_pt2 = tag_pt2,\n",
    "                                               partition = partition,\n",
    "                                               acct = acct,\n",
    "                                               mem_per_cpu = \"2G\",\n",
    "                                               cluster_specific_parameters = cluster_specific_parameters,\n",
    "                                               nodes = nodes, ntasks_per_node = ntasks_per_node,\n",
    "                                               time = time, module_load_conda = module_load_conda)\n",
    "\n",
    "          #cat(\"\\n\")\n",
    "          cat(script_info$script)\n",
    "\n",
    "          writeLines(script_info$script, script_info$path)\n",
    "\n",
    "          # Submit the SLURM job using the sbatch command\n",
    "          system(paste(\"sbatch\", script_info$path))\n",
    "\n",
    "          # Implement job submission limits and intervals if necessary\n",
    "          sleeptime <- 61\n",
    "\n",
    "          message(paste0(\"Sleeping for \", sleeptime, \" seconds\"))\n",
    "          Sys.sleep(sleeptime)\n",
    "          cat(\"\\n\")\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5371a450-78e9-4625-bc65-67fc22693584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'shared'"
      ],
      "text/latex": [
       "'shared'"
      ],
      "text/markdown": [
       "'shared'"
      ],
      "text/plain": [
       "[1] \"shared\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d42889af-e0fb-43b7-9ea0-f84c90aacbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'jhu152'"
      ],
      "text/latex": [
       "'jhu152'"
      ],
      "text/markdown": [
       "'jhu152'"
      ],
      "text/plain": [
       "[1] \"jhu152\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25710dca-4865-48ee-81a4-95f59c3dac30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
